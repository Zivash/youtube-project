{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7e3c05c2",
   "metadata": {},
   "source": [
    "# **Crawling**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dea9961",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import pandas as pd\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bbf3e67",
   "metadata": {},
   "outputs": [],
   "source": [
    "#crawling in kworb.net\n",
    "Home_page_url = \"https://kworb.net\"\n",
    "\n",
    "response1 = requests.get(Home_page_url)\n",
    "soup1 = BeautifulSoup(response1.content, \"html.parser\")\n",
    "urls = soup1.find(\"div\",attrs = {\"class\":\"subcontainer\"})\n",
    "\n",
    "for url in urls.find_all(\"a\"):\n",
    "    if url.get_text()==\"YOUTUBE\":\n",
    "        youtube_overview = Home_page_url + url[\"href\"]\n",
    "\n",
    "response2 = requests.get(youtube_overview)\n",
    "soup2 = BeautifulSoup(response2.content, \"html.parser\")\n",
    "Toplists = soup2.find(\"ul\",attrs = {\"class\":\"yt\"})\n",
    "for Toplist in Toplists.find_all(\"a\"):\n",
    "        if Toplist.get_text()==\"Top Lists\":\n",
    "            newlink = Home_page_url + Toplist[\"href\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc10d665",
   "metadata": {},
   "outputs": [],
   "source": [
    "response3 = requests.get(newlink)\n",
    "\n",
    "soup3 = BeautifulSoup(response3.content, \"html.parser\")\n",
    "links=[]\n",
    "find_published_year=[]\n",
    "links_by_year = soup3.findAll(\"div\",attrs = {\"class\":\"subcontainer\"})\n",
    "year=\"2022\"\n",
    "flag = 0\n",
    "\n",
    "for link_by_year in links_by_year:\n",
    "    for years in link_by_year.find_all(\"a\"):\n",
    "        if years.get_text() == year and flag >= 0:\n",
    "            flag = 1\n",
    "        \n",
    "        if years.get_text() == \"Earlier\":\n",
    "            flag = -1\n",
    "                \n",
    "        if flag == 1:\n",
    "            find_published_year.append(years[\"href\"])\n",
    "\n",
    "find_published_year = find_published_year[13:]\n",
    "for element in find_published_year:\n",
    "    links.append(Home_page_url + \"/youtube/\" + element)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41049663",
   "metadata": {},
   "outputs": [],
   "source": [
    "song_names =[]\n",
    "channel_names =[] \n",
    "duration_times= []\n",
    "published_dates=[]\n",
    "published_times=[]\n",
    "views_count=[]\n",
    "likes_count=[]\n",
    "comments_count=[]\n",
    "subscribes_count=[]\n",
    "lang=[]\n",
    "published_channel_dates = []\n",
    "total_views_channel = []\n",
    "channel_country = []\n",
    "video_count= []\n",
    "num_countries=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b122c1f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0,12):\n",
    "    responseSongs = requests.get(links[i])\n",
    "    soupSongs = BeautifulSoup(responseSongs.content, \"html.parser\")\n",
    "    table = soupSongs.findAll(\"td\",attrs = {\"class\":\"text\"})\n",
    "    \n",
    "    for song in table:\n",
    "        songDetail = Home_page_url + \"/youtube/\" + song.find(\"a\")[\"href\"]\n",
    "        responseForYTLink = requests.get(songDetail)\n",
    "        soupForYTLink = BeautifulSoup(responseForYTLink.content, \"html.parser\")\n",
    "        findurl  = soupForYTLink.find(\"iframe\")[\"src\"]\n",
    "        findurl = findurl.replace(\"embed/\", \"watch?v=\").replace(\"?rel=0\",\"\")\n",
    "        checkresponseYT = requests.get(findurl)\n",
    "        checksoup = BeautifulSoup(checkresponseYT.content, \"html.parser\")\n",
    "        try: #check if find the videoID\n",
    "            ch = checksoup.findAll(\"div\",attrs = {\"class\":\"watch-main-col\"})\n",
    "            for findID in ch:\n",
    "                saveID = findID.find(\"meta\",attrs = {\"itemprop\":\"videoId\"}).attrs['content']\n",
    "                Countries = ((findID.find(\"meta\",attrs = {\"itemprop\":\"regionsAllowed\"}).attrs['content']).count(\",\"))+1\n",
    "            ress = requests.get(\"https://youtube.googleapis.com/youtube/v3/videos?part=snippet%2CcontentDetails%2Cstatistics&id=\"+saveID+\"&key=AIzaSyD21rHmEqydeNQMInNJ5qWkgCZ_BtdJCrQ\")        \n",
    "            response_dict = json.loads(ress.text)\n",
    "            \n",
    "            try: #check if find the channelId\n",
    "                channelId = response_dict['items'][0]['snippet']['channelId']\n",
    "                channelIdUrl = \"https://www.youtube.com/channel/\" + channelId\n",
    "                response4 = requests.get(channelIdUrl)\n",
    "                soup4 = BeautifulSoup(response4.content, \"html.parser\")\n",
    "                channelName = soup4.find(\"meta\",attrs = {\"property\":\"og:title\"}).attrs['content'] #crawling\n",
    "                resChannel=requests.get(\"https://youtube.googleapis.com/youtube/v3/channels?part=snippet%2CcontentDetails%2Cstatistics&id=\" + channelId + \"&key=AIzaSyD21rHmEqydeNQMInNJ5qWkgCZ_BtdJCrQ\")\n",
    "                resChannel_dict = json.loads(resChannel.text)\n",
    "            except:\n",
    "                pass\n",
    "        except:\n",
    "            continue #if did not find the videoID\n",
    "        \n",
    "        #video\n",
    "        try:\n",
    "            num_countries.append(Countries)\n",
    "        except:\n",
    "            num_countries.append(np.nan)\n",
    "        try:\n",
    "            published_dates.append((response_dict['items'][0]['snippet']['publishedAt'])[:10])\n",
    "        except:\n",
    "            published_dates.append(np.nan)\n",
    "        try:\n",
    "            published_times.append(((response_dict['items'][0]['snippet']['publishedAt'])[11:])[:-1])\n",
    "        except:\n",
    "            published_times.append(np.nan)\n",
    "        try:\n",
    "            song_names.append(response_dict['items'][0]['snippet']['title'])\n",
    "        except:\n",
    "            song_names.append(np.nan)\n",
    "        try:\n",
    "            lang.append(response_dict['items'][0]['snippet']['defaultAudioLanguage'])\n",
    "        except:\n",
    "            lang.append(np.nan)\n",
    "        try:\n",
    "            duration_times.append((((response_dict['items'][0]['contentDetails']['duration'])[2:])[:-1]).replace(\"M\",\":\"))\n",
    "        except:\n",
    "            duration_times.append(np.nan)\n",
    "        try:\n",
    "            views_count.append(response_dict['items'][0]['statistics']['viewCount'])\n",
    "        except:\n",
    "            views_count.append(np.nan)\n",
    "        try:\n",
    "            likes_count.append(response_dict['items'][0]['statistics']['likeCount'])\n",
    "        except:\n",
    "            likes_count.append(np.nan)\n",
    "        try:\n",
    "            comments_count.append(response_dict['items'][0]['statistics']['commentCount'])\n",
    "        except:\n",
    "            comments_count.append(np.nan)\n",
    "        \n",
    "        #channel\n",
    "        try:\n",
    "            channel_names.append(channelName)\n",
    "        except:\n",
    "            channel_names.append(np.nan)\n",
    "        try:\n",
    "            subscribes_count.append(resChannel_dict['items'][0]['statistics']['subscriberCount'])\n",
    "        except:\n",
    "            subscribes_count.append(np.nan)\n",
    "        try:\n",
    "            published_channel_dates.append((resChannel_dict['items'][0]['snippet']['publishedAt'])[:-10])\n",
    "        except:\n",
    "            published_channel_dates.append(np.nan)\n",
    "        try:\n",
    "            total_views_channel.append(resChannel_dict['items'][0]['statistics']['viewCount'])\n",
    "        except:\n",
    "            total_views_channel.append(np.nan)\n",
    "        try:\n",
    "            channel_country.append(resChannel_dict['items'][0]['snippet']['country'])\n",
    "        except:\n",
    "            channel_country.append(np.nan)\n",
    "        try:\n",
    "            video_count.append(resChannel_dict['items'][0]['statistics']['videoCount'])\n",
    "        except:\n",
    "            video_count.append(np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67bd1a9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({\"Song Name\":song_names,\"Published Date\":published_dates,\"Published Time\":published_times,\"Duartion Time\":duration_times,\"Views\":views_count,\"Likes\":likes_count,\"Comments\":comments_count,\"Language\":lang,\"Countries Allowed\":num_countries,\"Channel Name\":channel_names,\"Channel Country\":channel_country,\"Channel Publihed Date\":published_channel_dates,\"Subscribes\":subscribes_count,\"Video Count\":video_count,\"Total Views\":total_views_channel})\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7a998e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"project.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d066eed8",
   "metadata": {},
   "source": [
    "# **Cleaning Table**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ea7fea3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.read_csv(\"project.csv\")\n",
    "df1 = df1.drop(df1.columns[0],axis=1)\n",
    "df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ddc9e94",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d609926a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = df1[df1[\"Language\"].notna()]\n",
    "df1.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c68640cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop duplicate with same name songs\n",
    "\n",
    "df1 = df1.drop_duplicates(subset = 'Song Name')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2381b9e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# change NAN in Channel Country\n",
    "\n",
    "df1[\"Channel Country\"] = df1[\"Channel Country\"].fillna(method='bfill')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a5cf1ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# change NAN in comments and likes\n",
    "\n",
    "df1[\"Likes\"] = df1[\"Likes\"].fillna(value = df1[\"Likes\"].mean())\n",
    "df1[\"Comments\"] = df1[\"Comments\"].fillna(value = df1[\"Comments\"].mean())\n",
    "df1.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1f07a29",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Convert Song Name to numeric\n",
    "\n",
    "for i, row in df1.iterrows():\n",
    "    df1.at[i, 'Song Name'] = i\n",
    "df1[\"Song Name\"] = pd.to_numeric(df1[\"Song Name\"], errors=\"coerce\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9afb49e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Convert Published Date to nomeric\n",
    "\n",
    "df1[\"Published Date\"] = df1[\"Published Date\"].str[6:]\n",
    "df1[\"Published Date\"] = pd.to_numeric(df1[\"Published Date\"], errors=\"coerce\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eca3092c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Convert Published Time to numeric\n",
    "\n",
    "df1[\"Published Time\"] = df1[\"Published Time\"].str[:-6]\n",
    "df1[\"Published Time\"] = pd.to_numeric(df1[\"Published Time\"], errors=\"coerce\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d32fe8fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Convert Duartion Time to numeric\n",
    "\n",
    "num_min = df1[\"Duartion Time\"].str[:-3]\n",
    "num_min = pd.to_numeric(num_min, errors=\"coerce\")\n",
    "num_sec = df1[\"Duartion Time\"].str[3:]\n",
    "num_sec = pd.to_numeric(num_sec, errors=\"coerce\")\n",
    "df1[\"Duartion Time\"] = round(num_min + (num_sec)/60,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec88d5df",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Convert Language,Channel Name and Country\n",
    "\n",
    "df1[\"Language\"] = LabelEncoder().fit_transform(df1[\"Language\"])\n",
    "df1[\"Channel Name\"] = LabelEncoder().fit_transform(df1[\"Channel Name\"])\n",
    "df1[\"Channel Country\"] = LabelEncoder().fit_transform(df1[\"Channel Country\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd5845fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Convert Channel Published Date to nomeric\n",
    "\n",
    "df1[\"Channel Published Date\"] = df1[\"Channel Published Date\"].str[6:]\n",
    "df1[\"Channel Published Date\"] = pd.to_numeric(df1[\"Channel Published Date\"], errors=\"coerce\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af8e8b31",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "506514ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = df1[df1[\"Duartion Time\"].notna()]\n",
    "df1 = df1[df1[\"Channel Published Date\"].notna()]\n",
    "df1.to_csv(\"Final Clean.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1580347f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96680c56",
   "metadata": {},
   "source": [
    "# **EDA**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5384f2a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from mpl_toolkits.mplot3d import Axes3D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e30cf67",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"Final Clean.csv\")\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f0de638",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Published Date'].hist(bins=13, grid = False, rwidth=0.9, color ='darkblue')\n",
    "plt.xlabel('Published Date')\n",
    "plt.ylabel('Video')\n",
    "plt.title('Videos per year')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ae48e3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "k=df.groupby(['Views']).mean()[['Likes','Comments']]\n",
    "k.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f704f803",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.Views.hist(bins=200,color = 'green')\n",
    "plt.xlabel('Views')\n",
    "plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09ec7410",
   "metadata": {},
   "outputs": [],
   "source": [
    "value_counts = df['Language'].value_counts()\n",
    "plt.pie([value_counts[7], df.shape[0]-value_counts[7]], labels=['English', 'Other Languages'],colors = ['red','orange'],  startangle=90, autopct='%1.1f%%')\n",
    "plt.axis('equal')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "628472c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"Duartion Time\"].hist(bins=50,color='lightblue')\n",
    "plt.xlabel('Duartion Time')\n",
    "plt.title('Duartion Time Frequency')\n",
    "plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb64bd58",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.scatterplot(x = 'Channel Published Date', y = 'Subscribes',s=50,color = 'purple',data = df)\n",
    "plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41fff8bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped = df.groupby(\"Published Date\").mean()# Plot the data\n",
    "grouped.plot(kind='bar', y='Views',color = 'brown')# Add a title and labels to the x and y axes\n",
    "plt.title(\"Average Number of Views per Year\")\n",
    "plt.xlabel(\"Year\")\n",
    "plt.ylabel(\"Number of Views\")# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7575d7d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = pd.DataFrame(df, columns = ['Views','Likes', 'Comments', 'Video Count'])\n",
    "sns.heatmap(df2.corr(), annot=True, cmap='Greens')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d1fc8ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(8,3))\n",
    "sns.boxplot(df[\"Countries Allowed\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac6e54e4",
   "metadata": {},
   "source": [
    "# **Machine Learning**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a687bae9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "521488e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"Final Clean.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f298579c",
   "metadata": {},
   "outputs": [],
   "source": [
    "regressor=LinearRegression()\n",
    "\n",
    "X=df[df.columns[df.columns != 'Views']]\n",
    "Y=df[['Views']]\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X,Y,random_state=42,test_size=0.2)\n",
    "\n",
    "regressor.fit(X_train , Y_train)\n",
    "\n",
    "Y_pred=regressor.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cd13684",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.regplot(Y_test, Y_pred, scatter_kws={'color':'green'}, line_kws={'color':'black'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ff63d79",
   "metadata": {},
   "outputs": [],
   "source": [
    "regressor.score(X_test,Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af6a2d2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "X=df[['Subscribes','Likes','Comments','Published Date','Language','Channel Country','Video Count']]\n",
    "Y=df[['Views']]\n",
    "X_train , X_test , Y_train , Y_test = train_test_split(X,Y,random_state=42,test_size=0.2)\n",
    "\n",
    "regressor.fit(X_train , Y_train)\n",
    "Y_pred=regressor.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df32e866",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.regplot(Y_test, Y_pred, scatter_kws={'color':'red'}, line_kws={'color':'black'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76f7e9fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "regressor.score(X_test,Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d18ca95",
   "metadata": {},
   "outputs": [],
   "source": [
    "regressor=LinearRegression()\n",
    "\n",
    "X=df[['Subscribes','Likes','Comments','Published Date','Language','Channel Country','Video Count', 'Channel Name','Duartion Time']]\n",
    "Y=df[['Views']]\n",
    "X_train , X_test , Y_train , Y_test = train_test_split(X,Y,random_state=42,test_size=0.2)\n",
    "\n",
    "regressor.fit(X_train , Y_train)\n",
    "\n",
    "Y_pred=regressor.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8315a4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.regplot(Y_test, Y_pred, scatter_kws={'color':'blue'}, line_kws={'color':'black'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee81f3b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "regressor.score(X_test,Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "418040f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "regressor=LinearRegression()\n",
    "\n",
    "X=df[['Subscribes','Likes','Comments','Published Date','Language','Channel Country','Channel Name']]\n",
    "Y=df[['Views']]\n",
    "X_train , X_test , Y_train , Y_test = train_test_split(X,Y,random_state=42,test_size=0.2)\n",
    "regressor.fit(X_train , Y_train)\n",
    "\n",
    "Y_pred=regressor.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34ac9906",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.regplot(Y_test, Y_pred, scatter_kws={'color':'lightblue'}, line_kws={'color':'black'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58a937ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "regressor.score(X_test,Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25bb2f00",
   "metadata": {},
   "outputs": [],
   "source": [
    "#random Forest:\n",
    "X=df[df.columns[df.columns != 'Views']]\n",
    "Y=df[['Views']]\n",
    "X_train , X_test , Y_train , Y_test = train_test_split(X,Y,random_state=42,test_size=0.2)\n",
    "regressor = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "regressor.fit(X_train, Y_train)\n",
    "print(regressor.score(X_test, Y_test))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
